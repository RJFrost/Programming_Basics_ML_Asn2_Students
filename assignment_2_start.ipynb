{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections.abc import MutableSequence\n",
    "import pandas as pd\n",
    "from abc import ABC, abstractmethod\n",
    "from statistics import stdev, mean\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #2 - With Bonus Stats!!\n",
    "\n",
    "## Overview\n",
    "\n",
    "The end goal for this is to create a special data structure that will be a list of numbers plus some extra math stuff, as well as the code to support using and testing everything. Each of these lists, here called a calculationList, will have two main parts - a list of numbers and a threshold value. Each type of object will work differently depending on its type, but the basic logic is the same. The threshold value is a limit for whatever type of calculation the list belongs to, so for a stdList, the threshold applies to the standard deviation, for a meanList, the threshold applies to the mean, etc. The calculation list should have a prune() method that will start removing values from the list until the relevant value is below the threshold. Each type of calculation list will have a different way of figuring out what to remove, as we want to remove the most \"important\" values first - i.e. if the standard deviation is greater than the threshold, and we have a value that is 3 standard deviations away from the mean and another that is 10 standard deviations away from the mean, we want to remove the second value first as it will be the most impactful. \n",
    "\n",
    "<b>Note: please let me know if the premise isn't clear. You should have to sort out some ambiguities as you develop, but the goal should be clear.</b>\n",
    "\n",
    "### Classes to Create\n",
    "\n",
    "A caclulationList class that is made up of a list of float numbers as well as a few additions. This class will inherit from two things - the mutable sequence class and the ABC class. The mutable sequence class will allow us to use the list methods, and the ABC class will allow us to use the abstract methods.\n",
    "\n",
    "The calculation list will be a base class that will not be implemented directly. You will need to create some subclasses that then inherit from the calculationList class. These subclasses will be the following:\n",
    "<ul>\n",
    "<li> stdList - this will be a calculationList that will prune values based on the standard deviation of the list. </li>\n",
    "<li> meanList - this will be a calculationList that will prune values based on the mean of the list. </li>\n",
    "<li> sumList - this will be a calculationList that will prune values based on the sum of the list. </li>\n",
    "</ul>\n",
    "\n",
    "Each of these classes should only add what they need to make their unique functionality work, the things that are common to all of them should be in the calculationList class. The top level calcList class is similar to the example listBasedSet class here: https://python.readthedocs.io/en/latest/library/collections.abc.html The other classes should be children of that class, each adding their own unique parts. One note, there may be erroneous values in the input data, so there should be some error checking to deal with broken inputs - <b>if a row has erroneous data, that row should be skipped entirely. </b>\n",
    "\n",
    "#### Example Results\n",
    "\n",
    "Here are a few screenshots of the processing logic of the calculation lists:\n",
    "\n",
    "![Calculation List Example](example_results.png \"Calculation List Example\")\n",
    "\n",
    "We can also look at the inputs and outputs of the calculation lists to see some of the details:\n",
    "\n",
    "![Input and Output Example](input_output.png \"Input and Output Example\")\n",
    "\n",
    "Please check with me if the idea and the goal is not clear. \n",
    "\n",
    "## Deliverables\n",
    "\n",
    "For this assignment, please submit the following:\n",
    "<ul>\n",
    "<li> The notebook file containing your code. </li>\n",
    "<li> The CSV output file, <b>generated from a test file that I'll post before the due date.</b> This file will be in the same format as the test data, but the values will be different. </li>\n",
    "</ul>\n",
    "\n",
    "## Grading\n",
    "\n",
    "The grading for this will be broken out as follows, and will learn heavily on things working correctly. \n",
    "<ul>\n",
    "<li> 75% - Functionality. If yours works, this is the baseline. If it fails, I may decrease this, depending on what I can visually spot in code. </li>\n",
    "<li> 25% - Code clarity and formatting. </li>\n",
    "</ul>\n",
    "\n",
    "### Notes and Hints\n",
    "\n",
    "I will put any update notes, responses to common questions, and relevant hints in a list in the README file. Please don't edit that file, as that will let you pull it to get new stuff without conflict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class calcList(MutableSequence, ABC):\n",
    "    def __init__(self, name, threshold, iterable, trim=3):\n",
    "        self._name = name\n",
    "        self._threshold = threshold\n",
    "        self._trim = trim\n",
    "        self.elements = list(iterable)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.elements[index]\n",
    "\n",
    "    def __setitem__(self, index, value):\n",
    "        self.elements[index] = value\n",
    "\n",
    "    def __delitem__(self, index):\n",
    "        del self.elements[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.elements)\n",
    "\n",
    "    def insert(self, index, value):\n",
    "        self.elements.insert(index, value)\n",
    "\n",
    "    def csv_output(self):\n",
    "        return f\"{self._name},{len(self)},{self._threshold},{self.value()}\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def value(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def prune(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def isPruned(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def returnType(self):\n",
    "        pass\n",
    "\n",
    "    def setThreshold(self, threshold):\n",
    "        self._threshold = threshold\n",
    "\n",
    "    def getThreshold(self):\n",
    "        return self._threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import stdev, mean\n",
    "\n",
    "class stdList(calcList):\n",
    "    def value(self):\n",
    "        if len(self.elements) > 1:\n",
    "            return stdev(self.elements)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def prune(self):\n",
    "        while self.value() > self._threshold:\n",
    "            mean_val = mean(self.elements)\n",
    "            max_deviation = max(self.elements, key=lambda x: abs(x - mean_val))\n",
    "            self.elements.remove(max_deviation)\n",
    "\n",
    "    def isPruned(self):\n",
    "        return self.value() <= self._threshold\n",
    "\n",
    "    def returnType(self):\n",
    "        return 'stdList'\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self._name} - Std. Dev: {self.value()} (Thresh: {self._threshold}) {self.elements}\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "class meanList(calcList):\n",
    "    def value(self):\n",
    "        if not self.elements:\n",
    "            return 0  # Return a default value or handle as needed for an empty list\n",
    "        else:\n",
    "            return mean(self.elements)\n",
    "\n",
    "    def prune(self):\n",
    "        while self.value() > self._threshold:\n",
    "            self.elements.remove(min(self.elements, key=lambda x: abs(x - self.value())))\n",
    "\n",
    "    def isPruned(self):\n",
    "        return self.value() <= self._threshold\n",
    "\n",
    "    def returnType(self):\n",
    "        return 'meanList'\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self._name} - Mean: {self.value()} (Thresh: {self._threshold}) {self.elements}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sumList(calcList):\n",
    "    def value(self):\n",
    "        return sum(self.elements)\n",
    "\n",
    "    def prune(self):\n",
    "        while self.value() > self._threshold:\n",
    "            self.elements.remove(max(self.elements, key=lambda x: abs(x - self.value())))\n",
    "\n",
    "    def isPruned(self):\n",
    "        return self.value() <= self._threshold\n",
    "\n",
    "    def returnType(self):\n",
    "        return 'sumList'\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self._name} - Sum: {self.value()} (Thresh: {self._threshold}) {self.elements}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Unit Tests\n",
    "\n",
    "These are some simple tests that you can use to check, if you want. Please feel free to change, remove, or add to these as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test - Std. Dev: 3.0276503540974917 (Thresh: 3) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "test - Std. Dev: 2.7386127875258306 (Thresh: 3) [2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "calc = stdList(\"test\", 3, [1,2,3,4,5,6,7,8,9,10])\n",
    "print(calc)\n",
    "calc.prune()\n",
    "print(calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test2 - Mean: 5.5 (Thresh: 4) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "test2 - Mean: 0 (Thresh: 4) []\n"
     ]
    }
   ],
   "source": [
    "calc2 = meanList(\"test2\", 4, [1,2,3,4,5,6,7,8,9,10])\n",
    "print(calc2)\n",
    "calc2.prune()\n",
    "print(calc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test3 - Sum: 55 (Thresh: 45) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "test3 - Sum: 45 (Thresh: 45) [5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "calc3 = sumList(\"test3\", 45, [1,2,3,4,5,6,7,8,9,10])\n",
    "print(calc3)\n",
    "calc3.prune()\n",
    "print(calc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Test\n",
    "\n",
    "The functions below are a simple test function for your code, it'll take in an input and an output and score the two. In your code, you'll have half of the inputs here, the expected results, and will need to write the rest of the code to generate your results and input them to run the test. \n",
    "\n",
    "This function can likely be wrapped in another, one that calls your code to generate that input to check against. This isn't required, but will likely make things easier to call and test repeatedly. You'd have to do everything required to get the \"response\" argument, which is the CSV file of your answers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testHarness(response, expected, response_col=\"Value\", expected_col=\"Value\", match_thresh=.03, exp_name=\"Name\", resp_name=\"Name\"):\n",
    "    '''Runs a test of the response file against the expected file. Returns a tuple of the number of correct and incorrect responses.'''\n",
    "    resp = pd.read_csv(response)\n",
    "    exp = pd.read_csv(expected)\n",
    "    \n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(resp):\n",
    "        exp_val = exp.iloc[i][expected_col]\n",
    "        resp_val = resp.iloc[i][response_col]\n",
    "        \n",
    "        if toleranceMatch(exp_val, resp_val, match_thresh) and (exp.iloc[i][exp_name] == resp.iloc[i][resp_name]):\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "        i += 1\n",
    "    \n",
    "    return (correct, incorrect)\n",
    "    \n",
    "\n",
    "def toleranceMatch(val1, val2, percent_tolerance):\n",
    "    '''Returns True if val1 and val2 are within percent_tolerance of each other, False otherwise.'''\n",
    "    if val1 == val2:\n",
    "        return True\n",
    "    else:\n",
    "        if val1 == 0:\n",
    "            if val2 == 0:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        if (abs(val1 - val2) / val1) <= percent_tolerance:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Length</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>List_0</td>\n",
       "      <td>5</td>\n",
       "      <td>30.19605769</td>\n",
       "      <td>15.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>List_1</td>\n",
       "      <td>9</td>\n",
       "      <td>37.83299154</td>\n",
       "      <td>29.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>List_2</td>\n",
       "      <td>44</td>\n",
       "      <td>42.90158192</td>\n",
       "      <td>42.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>List_3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1428.622569</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>List_4</td>\n",
       "      <td>8</td>\n",
       "      <td>13.75396487</td>\n",
       "      <td>12.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name Length     Threshold   Value\n",
       "0  List_0      5   30.19605769  15.001\n",
       "1  List_1      9   37.83299154  29.911\n",
       "2  List_2     44   42.90158192  42.091\n",
       "3  List_3      2  -1428.622569     0.0\n",
       "4  List_4      8   13.75396487   12.75"
      ]
     },
     "execution_count": 1052,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample exectution - you can change this to test your code\n",
    "# The functions here are things I made to both:\n",
    "# - read data from disk, and create a list of the calculation lists.\n",
    "# - process those lists to get actual outputs. \n",
    "#outputs = processCalculationLists(calculationListLoader(\"inputs.csv\"), output_file=\"output.csv\")\n",
    "#outputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12860\\3125109881.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Read data from disk and create calculation lists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcalc_lists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculationListLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"inputs.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Process the loaded calculation lists and store the outputs in 'output.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocessCalculationLists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalc_lists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"output.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Display the first few rows of the outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12860\\2413001468.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(calculation_lists, output_file)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# For example, if you're using Pandas DataFrames:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Processing logic to create 'output_data' DataFrame from 'calculation_lists'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0moutput_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Your processing logic here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Save the output data to a CSV file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0moutput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\2rory\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    840\u001b[0m                 )\n\u001b[0;32m    841\u001b[0m         \u001b[1;31m# For data is scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 844\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DataFrame constructor not properly called!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m             \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "# Read data from disk and create calculation lists\n",
    "calc_lists = calculationListLoader(\"inputs.csv\")\n",
    "\n",
    "# Process the loaded calculation lists and store the outputs in 'output.csv'\n",
    "outputs = processCalculationLists(calc_lists, output_file=\"output.csv\")\n",
    "\n",
    "# Display the first few rows of the outputs\n",
    "print(outputs.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truths = pd.read_csv(\"diffs.csv\")[\"0\"]\n",
    "submissions = pd.read_csv(\"difference.csv\")[\"0\"]\n",
    "\n",
    "print(verifyDifferences(submissions, truths))\n",
    "print(\"Score:\", (1 - len(verifyDifferences(submissions, truths))/len(truths))*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests = testHarness(\"output2.csv\", \"output2.csv\")\n",
    "tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
